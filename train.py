"""
MiniMind DDP è®­ç»ƒè„šæœ¬ - ä½¿ç”¨ torchrun/DistributedDataParallel (DDP)
ç›¸æ¯” nn.DataParallelï¼ŒDDP å…·æœ‰æ›´å¥½çš„æ€§èƒ½å’Œå†…å­˜æ•ˆç‡ã€‚
"""
import os
import argparse
from pathlib import Path

import torch
import torch.nn as nn
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP
from torch.utils.data import DataLoader, DistributedSampler
from torch.optim import AdamW
from torch.optim.lr_scheduler import CosineAnnealingLR
from tqdm import tqdm

from minimind import MiniMindConfig, MiniMindForCausalLM
from dataset import MiniMindTokenizerFast, NovelDatasetPreparator, MinimindDataset 


class Trainer:
    """MiniMind åˆ†å¸ƒå¼è®­ç»ƒå™¨ (DDP)"""
    
    def __init__(self, args, rank, world_size):
        self.args = args
        self.rank = rank
        self.world_size = world_size

        # æ ¸å¿ƒ DDP é€»è¾‘ï¼šä½¿ç”¨ local_rank ç»‘å®šåˆ°å”¯ä¸€çš„ GPU
        if args.local_rank == -1 or world_size == 0:
             # åœ¨ main() ä¸­å·²å¤„ç†è¯¥é”™è¯¯ï¼Œè¿™é‡Œä½œä¸ºäºŒæ¬¡æ£€æŸ¥
             raise ValueError("DDP ç¯å¢ƒåˆå§‹åŒ–å¤±è´¥ï¼šlocal_rank æ— æ•ˆæˆ– world_size ä¸º 0ã€‚")
        
        self.device = torch.device(f'cuda:{args.local_rank}')
        torch.cuda.set_device(self.device)
        
        # ä»…åœ¨ä¸»è¿›ç¨‹ä¸Šæ‰“å°ä¿¡æ¯
        if self.rank == 0:
            print(f"è®¾å¤‡: {self.device} (è¿›ç¨‹ {self.rank}/{self.world_size})")
        
        # --- åˆå§‹åŒ– Tokenizer å’Œ Config ---
        tokenizer_path = args.tokenizer_path
        # åªæœ‰ rank 0 æ£€æŸ¥å¹¶å‡†å¤‡æ–‡ä»¶
        if not os.path.exists(tokenizer_path) and self.rank == 0:
            print(f"âš ï¸  Tokenizer è·¯å¾„ä¸å­˜åœ¨: {tokenizer_path}ï¼Œå¯¹æ•°æ®é›†è¿›è¡Œè¯å…ƒå¤„ç†")
            preparator = NovelDatasetPreparator(
                dataset_dir=args.dataset_dir,
                pretrain_path=args.pretrain_path,
                chunk_size=args.chunk_size,
                chunk_overlap=args.chunk_overlap,
                tokenizer_path=args.tokenizer_path
            )
            preparator.prepare_dataset()
        
        # ç¡®ä¿ rank 0 å®Œæˆæ–‡ä»¶å‡†å¤‡åå†ç»§ç»­ï¼ˆé¿å…å…¶ä»–è¿›ç¨‹æ‰¾ä¸åˆ°æ–‡ä»¶ï¼‰
        if self.world_size > 1:
            dist.barrier() 

        self.tokenizer = MiniMindTokenizerFast.from_pretrained(tokenizer_path)
        
        # åˆå§‹åŒ–æ¨¡å‹é…ç½®
        config = MiniMindConfig(
            hidden_size=args.hidden_size,
            num_hidden_layers=args.num_layers,
            num_attention_heads=args.num_heads,
            vocab_size=self.tokenizer.vocab_size,
            max_position_embeddings=args.max_seq_len,
            dropout=args.dropout,
            use_moe=args.use_moe
        )
        # å°†æ¨¡å‹å®ä¾‹åŒ–å¹¶ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
        model = MiniMindForCausalLM(config).to(self.device)
        
        # --- æ£€æŸ¥ç‚¹å’Œé¢„è®­ç»ƒåŠ è½½ ---
        self.epoch = 0
        
        if args.resume_from_checkpoint and os.path.exists(args.output_dir):
            # æ³¨æ„ï¼šåœ¨ DDP ä¸­ï¼Œåªæœ‰ä¸»è¿›ç¨‹è¿›è¡Œæ–‡ä»¶ I/O
            checkpoint_path = Path(args.output_dir) / "minimind_model.pt"
            if checkpoint_path.exists():
                # ä½¿ç”¨ map_location ç¡®ä¿åŠ è½½åˆ°æ­£ç¡®çš„è®¾å¤‡
                checkpoint = torch.load(checkpoint_path, map_location=self.device)
                if isinstance(checkpoint, dict) and "model_state" in checkpoint:
                    model.load_state_dict(checkpoint["model_state"], strict=False)
                    self.epoch = checkpoint.get("epoch", 0)
                    if self.rank == 0:
                        print(f"ä»æ–­ç‚¹ç»§ç»­è®­ç»ƒï¼Œèµ·å§‹ epoch: {self.epoch}")
                else:
                    model.load_state_dict(checkpoint, strict=False)
            elif self.rank == 0:
                print(f"âš ï¸  æœªæ‰¾åˆ°æ–­ç‚¹æ–‡ä»¶: {checkpoint_path}")
        elif args.pretrained_path and os.path.exists(args.pretrained_path):
            model.load_state_dict(torch.load(args.pretrained_path, map_location=self.device), strict=False)
        
        # --- DDP åŒ…è£…æ¨¡å‹ ---
        # è¿™ä¸€æ­¥å°†æ¨¡å‹æ³¨å†Œåˆ°åˆ†å¸ƒå¼ç»„ä¸­
        self.model = DDP(model, device_ids=[args.local_rank])
        
        # --- ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨ ---
        self.optimizer = AdamW(self.model.parameters(), lr=args.learning_rate, weight_decay=args.weight_decay)
        self.scheduler = CosineAnnealingLR(self.optimizer, T_max=args.epochs, eta_min=args.min_lr) if args.use_scheduler else None
        
        # --- æ•°æ®åŠ è½½å™¨å’Œ Sampler ---
        if args.use_jsonl and os.path.exists(args.data_path):
            dataset = MinimindDataset(args.data_path, max_length=args.max_seq_len)
        else:
            raise FileNotFoundError(f"âš ï¸  æ•°æ®è·¯å¾„ä¸å­˜åœ¨æˆ–æœªæŒ‡å®š JSONL æ ¼å¼: {args.data_path}")
        
        # DDP: ä½¿ç”¨ DistributedSamplerï¼Œå®ƒæ ¹æ® self.rank å’Œ self.world_size åˆ’åˆ†æ•°æ®
        sampler = DistributedSampler(dataset, num_replicas=self.world_size, rank=self.rank, shuffle=True)
        
        self.dataloader = DataLoader(dataset, batch_size=args.batch_size, sampler=sampler,
                                     num_workers=args.num_workers, pin_memory=True)
        self.criterion = nn.CrossEntropyLoss(reduction='none')

    @property
    def base_model(self):
        """è¿”å›åŸºç¡€æ¨¡å‹å®ä¾‹ï¼Œå³ DDP åŒ…è£…ä¸‹çš„ .moduleã€‚"""
        return self.model.module

    def train(self):
        """æ‰§è¡Œè®­ç»ƒ"""
        if self.rank == 0:
            print("\nğŸš€ å¼€å§‹ DDP è®­ç»ƒ...\n")
        self.model.train()
        
        for epoch in range(self.epoch, self.args.epochs):
            # DDP: æ¯æ¬¡ epoch å¼€å§‹æ—¶è®¾ç½® Samplerï¼Œç¡®ä¿ä¸åŒ epoch å¾—åˆ°ä¸åŒçš„æ•°æ®é¡ºåº
            self.dataloader.sampler.set_epoch(epoch)
            
            if self.rank == 0:
                print(f"Epoch {epoch + 1}/{self.args.epochs}")
            
            total_loss = 0.0
            
            # ä»…åœ¨ä¸»è¿›ç¨‹ä¸Šä½¿ç”¨ tqdm
            data_iterator = tqdm(self.dataloader, desc="è®­ç»ƒ") if self.rank == 0 else self.dataloader
            
            for input_ids, labels, loss_mask in data_iterator:
                # æ¯ä¸ªè¿›ç¨‹å°†è‡ªå·±çš„æ•°æ®åŠ è½½åˆ°è‡ªå·±çš„ GPU ä¸Š
                input_ids = input_ids.to(self.device)
                labels = labels.to(self.device)
                loss_mask = loss_mask.to(self.device)
                
                outputs = self.model(input_ids)
                
                # ä½¿ç”¨ reduction='none' è®¡ç®—æ¯ä¸ªä½ç½®çš„æŸå¤±ï¼Œç„¶åé€šè¿‡ loss_mask åŠ æƒ
                loss = self.criterion(
                    outputs.logits.view(-1, self.base_model.config.vocab_size),
                    labels.view(-1)
                ).view(labels.size())
                
                # åº”ç”¨ loss_maskï¼Œå¿½ç•¥ padding ä½ç½®çš„æŸå¤±
                loss = (loss * loss_mask).sum() / loss_mask.sum()
                
                # å¦‚æœæ¨¡å‹æ”¯æŒè¾…åŠ©æŸå¤±ï¼ˆä¾‹å¦‚ MoEï¼‰ï¼Œæ·»åŠ è¾…åŠ©æŸå¤±
                if hasattr(outputs, 'aux_loss') and outputs.aux_loss is not None:
                    loss = loss + outputs.aux_loss
                
                self.optimizer.zero_grad()
                loss.backward()
                
                # æ¢¯åº¦è£å‰ªåœ¨ DDP æ¨¡å‹ä¸Šæ‰§è¡Œ
                if self.args.grad_clip > 0:
                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.args.grad_clip)
                
                self.optimizer.step()
                total_loss += loss.item()
                
                if self.rank == 0:
                    data_iterator.set_postfix({"loss": f"{loss.item():.4f}"})
            
            if self.scheduler:
                self.scheduler.step()
            
            # ä»…åœ¨ä¸»è¿›ç¨‹ä¸ŠæŠ¥å‘Šå¹³å‡æŸå¤±
            if self.rank == 0:
                avg_loss = total_loss / len(self.dataloader)
                print(f"å¹³å‡æŸå¤±: {avg_loss:.4f}\n")
            
            # æŒ‰é—´éš”ä¿å­˜æ¨¡å‹ï¼Œä»…åœ¨ä¸»è¿›ç¨‹ä¸Šæ‰§è¡Œ
            if self.rank == 0 and (epoch + 1) % self.args.save_interval == 0:
                self._save_model(epoch)
        
        if self.rank == 0:
            self._save_model(self.args.epochs - 1)
        
        # ç»“æŸè®­ç»ƒæ—¶é”€æ¯è¿›ç¨‹ç»„
        dist.destroy_process_group()
    
    def _save_model(self, epoch):
        """ä¿å­˜æ¨¡å‹ (ä»…åœ¨ rank 0 ä¸Šæ‰§è¡Œ)"""
        if self.rank != 0:
            return
            
        print(f"\nä¿å­˜æ¨¡å‹ (epoch {epoch})...")
        output_dir = Path(self.args.output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # ä½¿ç”¨ self.base_model è·å–æœªåŒ…è£…çš„æ¨¡å‹ (å³ DDP.module)
        model_state = self.base_model.state_dict()
        checkpoint = {
            "model_state": model_state,
            "epoch": epoch
        }
        torch.save(checkpoint, output_dir / "minimind_model.pt")
        
        # ä¿å­˜é…ç½®å’Œ tokenizer
        self.base_model.config.save_pretrained(str(output_dir))
        self.tokenizer.save_pretrained(str(output_dir / "tokenizer"))
        print(f"âœ… å·²ä¿å­˜åˆ°: {output_dir}")


def main():
    parser = argparse.ArgumentParser()
    
    # DDP/torchrun è‡ªåŠ¨è®¾ç½® local_rank
    # ä¿®å¤: ä»ç¯å¢ƒå˜é‡è·å– local_rankï¼Œå¦‚æœä¸å­˜åœ¨åˆ™é»˜è®¤ä¸º -1
    local_rank_env = os.environ.get("LOCAL_RANK")
    parser.add_argument("--local_rank", type=int, default=int(local_rank_env) if local_rank_env is not None else -1, help="Local rank is set by torchrun")
    
    # ... å…¶ä»–å‚æ•°ä¿æŒä¸å˜ ...
    # æ•°æ®å‡†å¤‡é…ç½®
    parser.add_argument("--dataset_dir", default="./dataset")
    parser.add_argument("--chunk_size", type=int, default=1024)
    parser.add_argument("--chunk_overlap", type=int, default=128)
    parser.add_argument("--vocab_size", type=int, default=6400)
    parser.add_argument("--tokenizer_path", type=str, default="./dataset/tokenizer")
    parser.add_argument("--pretrain_path", type=str, default="./dataset/pretrain.jsonl")
    
    # æ¨¡å‹é…ç½®
    parser.add_argument("--hidden_size", type=int, default=512)
    parser.add_argument("--num_layers", type=int, default=8)
    parser.add_argument("--num_heads", type=int, default=8)
    parser.add_argument("--max_seq_len", type=int, default=512)
    parser.add_argument("--dropout", type=float, default=0.1)
    parser.add_argument("--use_moe", action="store_true")
    
    # è®­ç»ƒé…ç½®
    parser.add_argument("--epochs", type=int, default=1)
    parser.add_argument("--batch_size", type=int, default=8)
    parser.add_argument("--learning_rate", type=float, default=1e-4)
    parser.add_argument("--min_lr", type=float, default=1e-6)
    parser.add_argument("--weight_decay", type=float, default=0.01)
    parser.add_argument("--grad_clip", type=float, default=1.0)
    parser.add_argument("--use_scheduler", action="store_true")
    
    # æ•°æ®é…ç½®
    parser.add_argument("--use_jsonl", action="store_true")
    parser.add_argument("--data_path", type=str, default="./dataset/pretrain.jsonl")
    
    # æ£€æŸ¥ç‚¹é…ç½®
    parser.add_argument("--save_interval", type=int, default=1, help="æ¯å¤šå°‘è½®ä¿å­˜ä¸€æ¬¡æ¨¡å‹")
    parser.add_argument("--resume_from_checkpoint", action="store_true", help="ä»ä¸Šæ¬¡ä¿å­˜çš„æ¨¡å‹ç»§ç»­è®­ç»ƒ")
    
    # å…¶ä»–é…ç½®
    parser.add_argument("--pretrained_path", type=str, default=None)
    parser.add_argument("--output_dir", type=str, default="./output")
    # DDP ç¯å¢ƒä¸­ device æ€»æ˜¯ "cuda"
    parser.add_argument("--device", type=str, default="cuda") 
    parser.add_argument("--gpu_ids", type=str, default=None, help="GPUè®¾å¤‡ç¼–å·ï¼Œåœ¨ DDP ä¸­é€šå¸¸ä¸éœ€è¦æ‰‹åŠ¨è®¾ç½®")
    parser.add_argument("--num_workers", type=int, default=2)
    
    args = parser.parse_args()
    
    # --- DDP åˆå§‹åŒ–æ£€æŸ¥ ---
    # å¦‚æœ local_rank æ˜¯ -1 ä¸”æ²¡æœ‰ WORLD_SIZE ç¯å¢ƒå˜é‡ï¼Œåˆ™è„šæœ¬æœªé€šè¿‡ torchrun æ­£ç¡®å¯åŠ¨
    if args.local_rank == -1 and 'WORLD_SIZE' not in os.environ:
        print("è‡´å‘½é”™è¯¯ï¼šæœªæ£€æµ‹åˆ° DDP ç¯å¢ƒå˜é‡ã€‚è¯·ä½¿ç”¨ 'torchrun --nproc_per_node=N train_ddp.py ...' å¯åŠ¨è„šæœ¬ã€‚")
        return # é€€å‡ºç¨‹åºï¼Œé¿å…ç»§ç»­æ‰§è¡Œ DDP åˆå§‹åŒ–
    
    # torchrun ä¼šè‡ªåŠ¨è®¾ç½®è¿™äº›ç¯å¢ƒå˜é‡ï¼Œå¹¶ç”± dist.init_process_group() è¯»å–
    dist.init_process_group(backend="nccl") 
    rank = dist.get_rank()
    world_size = dist.get_world_size()
    
    trainer = Trainer(args, rank, world_size)
    trainer.train()

if __name__ == "__main__":
    main()